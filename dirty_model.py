# -*- coding: utf-8 -*-
"""dirty_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bRmuJNycoayr-6xQaAzuXVKCW8t4S2Rl

<a href="https://colab.research.google.com/github/Arnold-Caleb/COVID-19/blob/master/dirty_model.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

# Commented out IPython magic to ensure Python compatibility.
# Mount google drive to the colab VM
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

#...
FOLDER_NAME = 'COVID-19'

assert FOLDER_NAME is not None, '[!] Enter the folder name'
# Python interpreter of the colab should now load
# .py files from within it
import sys 
sys.path.append('/content/drive/My drive/{}'.format(FOLDER_NAME))

# %cd drive/My\ Drive/$FOLDER_NAME

from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf

from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

from utilities import IMG_HEIGHT, IMG_WIDTH, EPOCHS, BATCH_SIZE, TRAIN_DIR, TEST_DIR, VAL_DIR
from utilities.plots import plotImages, learningCurve
from utilities.preprocess import preprocessImages
from utilities.imageloader import loadSingleImage, loadImages

import numpy as np

train_data_gen, val_data_gen, test_data_gen = preprocessImages(TRAIN_DIR,
                                                               VAL_DIR,
                                                               TEST_DIR,
                                                               BATCH_SIZE)

# Set up callbacks for the model's performance
checkpoint = ModelCheckpoint('dirty_covid_model.h5',
                             monitor='val_loss',
                             mode='min',
                             save_best_only=True,
                             verbose=1)

earlystop = EarlyStopping(monitor='val_loss',
                          min_delta=0,
                          patience=10,
                          verbose=1,
                          restore_best_weights=True,
                          )

reduce_lr = ReduceLROnPlateau(monitor='val_loss',
                              factor=0.1, 
                              patience=4, 
                              verbose=1,
                              min_delta=0.0001)

callbacks = [checkpoint, reduce_lr] # not including early stopping for now

training_images, training_labels = next(train_data_gen) 

plotImages(training_images[:5])

def create_model():
    model = Sequential()
    model.add(Conv2D(16, 3, padding='same', activation='relu', input_shape=(224, 224, 3)))
    model.add(MaxPooling2D())

    model.add(Conv2D(32, 3, padding='same', activation='relu'))
    model.add(MaxPooling2D())

    model.add(Conv2D(64, 3, padding='same', activation='relu'))
    model.add(MaxPooling2D())

    model.add(Flatten())
    model.add(Dropout(0.2))
    model.add(Dense(512, activation='relu'))

    model.add(Dropout(0.2))
    model.add(Dense(1024, activation='relu'))

    model.add(Dropout(0.2))
    model.add(Dense(3, activation='softmax'))
    
    return model

model = create_model()
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(train_data_gen, 
                    steps_per_epoch=int(np.ceil(train_data_gen.n / float(BATCH_SIZE))),
                    epochs=EPOCHS,
                    callbacks=callbacks,
                    validation_data=val_data_gen,
                    validation_steps=int(np.ceil(val_data_gen.n / float(BATCH_SIZE)))
                    )

acc, val_acc = history.history['accuracy'], history.history['val_accuracy']
loss, val_loss = history.history['loss'], history.history['val_loss']

epochs_range = range(EPOCHS)

learningCurve(epochs_range=epochs_range, 
              acc=acc, 
              val_acc=val_acc, 
              loss=loss, 
              val_loss=val_loss)

test_loss, test_acc = model.evaluate(test_data_gen)

# After building the model, time to test it on new data.
classifier = load_model('dirty_covid_model.h5')

classifier.evaluate(test_data_gen, verbose=1)